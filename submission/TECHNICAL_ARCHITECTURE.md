# üèóÔ∏è Douglas Mo Digital Twin - Technical Architecture

## üìê System Overview

The Digital Twin system is a multi-platform AI-powered professional portfolio with RAG (Retrieval-Augmented Generation) capabilities, designed to simulate interview conversations and provide intelligent responses about professional experience.

---

## üéØ Architecture Diagram

```mermaid
graph TB
    subgraph "User Interfaces"
        WEB[Web Browser]
        CLAUDE[Claude Desktop]
        VSCODE[VS Code]
    end
    
    subgraph "Frontend Layer"
        NEXTJS[Next.js 14 App Router]
        CHAT[ChatInterface Component]
        ADMIN[Admin Dashboard]
    end
    
    subgraph "API Layer"
        API_CHAT[/api/chat]
        API_ANALYTICS[/api/admin/analytics]
        API_LOGS[/api/admin/logs]
        MCP_SERVER[MCP Server]
    end
    
    subgraph "Business Logic"
        LLM_LIB[LLM Service]
        VECTOR_LIB[Vector DB Service]
        ANALYTICS_LIB[Analytics Engine]
    end
    
    subgraph "Data Layer"
        JSON[digitaltwin.json]
        UPSTASH[(Upstash Vector DB)]
        MEMORY[(In-Memory Store)]
    end
    
    subgraph "External Services"
        GROQ[Groq API - Llama 3.3 70B]
        VERCEL[Vercel Hosting]
    end
    
    WEB --> NEXTJS
    CLAUDE --> MCP_SERVER
    VSCODE --> MCP_SERVER
    
    NEXTJS --> CHAT
    NEXTJS --> ADMIN
    
    CHAT --> API_CHAT
    ADMIN --> API_ANALYTICS
    ADMIN --> API_LOGS
    
    API_CHAT --> LLM_LIB
    API_CHAT --> VECTOR_LIB
    API_CHAT --> ANALYTICS_LIB
    
    MCP_SERVER --> JSON
    
    LLM_LIB --> GROQ
    VECTOR_LIB --> UPSTASH
    VECTOR_LIB --> JSON
    ANALYTICS_LIB --> MEMORY
    
    NEXTJS -.deployment.-> VERCEL
```

---

## üîÑ Data Flow Architecture

### 1. User Query Processing Flow

```mermaid
sequenceDiagram
    participant User
    participant ChatUI as Chat Interface
    participant API as /api/chat
    participant Vector as Vector DB Service
    participant LLM as LLM Service
    participant Analytics as Analytics Engine
    
    User->>ChatUI: Submit question
    ChatUI->>ChatUI: Generate session ID
    ChatUI->>API: POST /api/chat
    
    API->>Analytics: Log interaction start
    API->>LLM: Analyze question type
    LLM-->>API: Return scenario type
    
    API->>Vector: Semantic search (query)
    Vector->>Vector: Generate embeddings
    Vector->>Upstash: Query top-k vectors
    Upstash-->>Vector: Return relevant chunks
    Vector-->>API: Return context (3-5 chunks)
    
    API->>LLM: Generate response (context + question)
    LLM->>Groq: API call with prompt
    Groq-->>LLM: AI-generated answer
    LLM-->>API: Formatted response
    
    API->>Analytics: Log interaction complete
    API-->>ChatUI: Return answer + metadata
    ChatUI-->>User: Display response
```

### 2. MCP Server Data Access Flow

```mermaid
sequenceDiagram
    participant Claude as Claude Desktop
    participant MCP as MCP Server
    participant JSON as digitaltwin.json
    
    Claude->>MCP: Tool call: get_work_experience
    MCP->>JSON: Read file
    JSON-->>MCP: Return data
    MCP->>MCP: Filter by company (if specified)
    MCP->>MCP: Format as JSON
    MCP-->>Claude: Return formatted data
    Claude->>Claude: Process and display
```

### 3. Admin Analytics Flow

```mermaid
sequenceDiagram
    participant Admin as Admin User
    participant Dashboard as Admin Dashboard
    participant API as /api/admin
    participant Analytics as Analytics Engine
    participant Memory as In-Memory Store
    
    Admin->>Dashboard: Access /admin
    Dashboard->>API: GET /api/admin/analytics
    API->>Analytics: Calculate metrics
    Analytics->>Memory: Query logs
    Memory-->>Analytics: Return raw data
    Analytics->>Analytics: Aggregate statistics
    Analytics-->>API: Return metrics
    API-->>Dashboard: JSON response
    Dashboard-->>Admin: Display charts & tables
```

---

## üóÇÔ∏è Data Schema

### digitaltwin.json Structure

```typescript
interface DigitalTwinData {
  personal: PersonalInfo;
  salary_location: SalaryLocationInfo;
  experience: WorkExperience[];
  education: Education[];
  skills: Skills;
  projects_portfolio: Project[];
  interview_prep: InterviewPrep;
}

interface WorkExperience {
  company: string;
  title: string;
  duration: string;
  location: string;
  company_context: string;
  team_structure: string;
  achievements_star: STARAchievement[];
  technical_skills_used: string[];
  leadership_examples?: string[];
  quantifiable_metrics: string[];
}

interface STARAchievement {
  situation: string;
  task: string;
  action: string;
  result: string;
}
```

### Vector Database Schema

```typescript
interface VectorMetadata {
  id: string;                    // Unique chunk ID
  type: ChunkType;               // Classification
  content: string;               // Text content for embedding
  source: string;                // Origin reference
  category?: string;             // Sub-classification
}

type ChunkType = 
  | 'personal' 
  | 'experience' 
  | 'skill' 
  | 'project' 
  | 'education' 
  | 'interview_prep';

// Example vector chunks:
// - exp-star-BF Suma-1: STAR achievement from BF Suma
// - skill-lang-Python: Python programming skills
// - interview-behavioral-1: Interview prep question
```

### Analytics Data Schema

```typescript
interface ChatLog {
  id: string;
  timestamp: string;
  question: string;
  answer: string;
  sessionId: string;
  interviewType: string;
  responseTime: number;          // milliseconds
  contextChunks: number;
  success: boolean;
  errorMessage?: string;
  userAgent: string;
  ipAddress: string;
}

interface VisitorSession {
  sessionId: string;
  firstVisit: string;
  lastVisit: string;
  pageViews: number;
  questionsAsked: number;
  avgResponseTime: number;
  devices: string[];
}

interface AnalyticsMetrics {
  totalVisitors: number;
  totalQuestions: number;
  avgResponseTime: number;
  successRate: number;
  topQuestions: Array<{question: string; count: number}>;
  interviewTypeDistribution: Record<string, number>;
  responseTimeDistribution: Record<string, number>;
  dailyStats: Array<{date: string; visitors: number; questions: number}>;
}
```

---

## üß© Component Architecture

### Frontend Components Hierarchy

```
app/
‚îú‚îÄ‚îÄ layout.tsx (Root Layout)
‚îÇ   ‚îî‚îÄ‚îÄ Metadata & Global Styles
‚îÇ
‚îú‚îÄ‚îÄ page.tsx (Main Landing Page)
‚îÇ   ‚îú‚îÄ‚îÄ Header Navigation
‚îÇ   ‚îú‚îÄ‚îÄ Hero Section
‚îÇ   ‚îú‚îÄ‚îÄ About Section
‚îÇ   ‚îú‚îÄ‚îÄ Experience Section
‚îÇ   ‚îú‚îÄ‚îÄ Skills Section
‚îÇ   ‚îú‚îÄ‚îÄ Education Section
‚îÇ   ‚îú‚îÄ‚îÄ AI Chat Section
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ <ChatInterface />
‚îÇ   ‚îî‚îÄ‚îÄ Footer
‚îÇ
‚îî‚îÄ‚îÄ admin/
    ‚îî‚îÄ‚îÄ page.tsx (Admin Dashboard)
        ‚îú‚îÄ‚îÄ Authentication Check
        ‚îú‚îÄ‚îÄ Metrics Cards
        ‚îú‚îÄ‚îÄ Interview Type Chart
        ‚îú‚îÄ‚îÄ Response Time Chart
        ‚îú‚îÄ‚îÄ Top Questions List
        ‚îî‚îÄ‚îÄ Chat Logs Table
            ‚îî‚îÄ‚îÄ Log Detail Modal

components/
‚îî‚îÄ‚îÄ ChatInterface.tsx
    ‚îú‚îÄ‚îÄ Message List
    ‚îú‚îÄ‚îÄ Input Form
    ‚îú‚îÄ‚îÄ Loading State
    ‚îî‚îÄ‚îÄ Session Management
```

### API Routes Architecture

```
app/api/
‚îú‚îÄ‚îÄ chat/
‚îÇ   ‚îî‚îÄ‚îÄ route.ts
‚îÇ       ‚îú‚îÄ‚îÄ POST handler
‚îÇ       ‚îú‚îÄ‚îÄ Question type analysis
‚îÇ       ‚îú‚îÄ‚îÄ Vector search
‚îÇ       ‚îú‚îÄ‚îÄ LLM generation
‚îÇ       ‚îî‚îÄ‚îÄ Analytics logging
‚îÇ
‚îî‚îÄ‚îÄ admin/
    ‚îú‚îÄ‚îÄ analytics/
    ‚îÇ   ‚îî‚îÄ‚îÄ route.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ GET handler (metrics)
    ‚îÇ       ‚îú‚îÄ‚îÄ POST handler (export)
    ‚îÇ       ‚îî‚îÄ‚îÄ Authentication
    ‚îÇ
    ‚îî‚îÄ‚îÄ logs/
        ‚îî‚îÄ‚îÄ route.ts
            ‚îú‚îÄ‚îÄ GET handler (list)
            ‚îú‚îÄ‚îÄ GET handler (search)
            ‚îî‚îÄ‚îÄ DELETE handler (clear)
```

---

## üîå Integration Points

### 1. Upstash Vector Database Integration

**Connection:**
```typescript
// lib/vectordb.ts
import { Index } from '@upstash/vector';

export const vectorIndex = new Index({
  url: process.env.UPSTASH_VECTOR_REST_URL,
  token: process.env.UPSTASH_VECTOR_REST_TOKEN,
});
```

**Operations:**
- `upsert()` - Upload vectors with metadata
- `query()` - Semantic search with top-k results
- `delete()` - Remove outdated chunks
- `fetch()` - Retrieve by ID

**Data Flow:**
1. JSON data ‚Üí Text chunks (32 chunks)
2. Chunks ‚Üí Vector embeddings (automatic)
3. Query ‚Üí Embedding ‚Üí Similarity search
4. Results ‚Üí Top 3-5 relevant chunks

### 2. Groq API Integration

**Connection:**
```typescript
// lib/llm.ts
import Groq from 'groq-sdk';

const groq = new Groq({
  apiKey: process.env.GROQ_API_KEY,
});
```

**Model Configuration:**
- Model: `llama-3.3-70b-versatile`
- Max tokens: 1000
- Temperature: 0.7
- Top-p: 0.9

**Prompt Engineering:**
```typescript
const systemPrompts = {
  screening: "You are a professional interviewer...",
  hr: "You are an HR professional...",
  technical: "You are a senior technical interviewer...",
  manager: "You are a hiring manager...",
  executive: "You are an executive interviewer..."
};
```

### 3. MCP Server Integration

**Protocol:** Model Context Protocol (stdio transport)

**Available Tools:**
- `get_personal_info()` - Personal data
- `get_work_experience(company?)` - Work history
- `get_education()` - Education background
- `get_skills(category?)` - Skills by type
- `get_projects()` - Project portfolio
- `get_interview_prep(section?)` - Interview materials
- `search_experience(keyword)` - Keyword search
- `generate_resume_summary(job_title, focus_areas?)` - Custom resume

**Resources:**
- `digitaltwin://personal`
- `digitaltwin://experience`
- `digitaltwin://education`
- `digitaltwin://skills`
- `digitaltwin://full-profile`

---

## üöÄ Deployment Architecture

### Multi-Platform Deployment Strategy

```mermaid
graph LR
    subgraph "Local Development"
        DEV[npm run dev]
        LOCAL[localhost:3000]
    end
    
    subgraph "GitHub"
        REPO[Repository]
        ACTIONS[GitHub Actions]
    end
    
    subgraph "Vercel Production"
        BUILD[Build Process]
        DEPLOY[Deployment]
        CDN[Global CDN]
        PROD[douglasmo.vercel.app]
    end
    
    subgraph "Claude Desktop"
        MCP[MCP Server]
        CONFIG[claude_desktop_config.json]
    end
    
    DEV --> LOCAL
    LOCAL --> REPO
    REPO --> ACTIONS
    ACTIONS --> BUILD
    BUILD --> DEPLOY
    DEPLOY --> CDN
    CDN --> PROD
    
    MCP --> CONFIG
```

### Environment Variables

```bash
# Production (Vercel)
UPSTASH_VECTOR_REST_URL=https://xxx.upstash.io
UPSTASH_VECTOR_REST_TOKEN=xxx
GROQ_API_KEY=gsk_xxx
ADMIN_PASSWORD=xxx

# Local Development
.env.local
.env
```

### Build Configuration

**next.config.js:**
```javascript
module.exports = {
  env: {
    UPSTASH_VECTOR_REST_URL: process.env.UPSTASH_VECTOR_REST_URL,
    UPSTASH_VECTOR_REST_TOKEN: process.env.UPSTASH_VECTOR_REST_TOKEN,
    GROQ_API_KEY: process.env.GROQ_API_KEY,
  },
  typescript: {
    ignoreBuildErrors: false,
  },
  eslint: {
    ignoreDuringBuilds: false,
  },
};
```

---

## üìä Performance Specifications

### Response Time Targets

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Vector Search | < 500ms | ~300ms | ‚úÖ |
| LLM Generation | < 1.5s | ~1.2s | ‚úÖ |
| Total Response | < 2s | ~1.8s | ‚úÖ |
| Page Load (FCP) | < 1.5s | ~1.2s | ‚úÖ |
| Admin Dashboard | < 1s | ~800ms | ‚úÖ |

### Scalability Metrics

| Resource | Limit | Usage | Capacity |
|----------|-------|-------|----------|
| Vercel Bandwidth | 100GB/month | ~5GB/month | 5% |
| Groq API Calls | 14,400/day | ~100/day | <1% |
| Vector DB Storage | 100K vectors | 32 vectors | <1% |
| Serverless Functions | 100 hrs/month | ~10 hrs/month | 10% |

---

## üîí Security Architecture

### Authentication & Authorization

```typescript
// Admin authentication
const ADMIN_PASSWORD = process.env.ADMIN_PASSWORD;

// Bearer token validation
const authHeader = request.headers.get('authorization');
if (!authHeader || authHeader !== `Bearer ${ADMIN_PASSWORD}`) {
  return Response.json({ error: 'Unauthorized' }, { status: 401 });
}
```

### Data Privacy

- **No PII storage** - Analytics use session IDs, not personal data
- **Environment variables** - API keys stored securely
- **Read-only MCP** - MCP server has read-only access
- **HTTPS only** - All communication encrypted

### API Rate Limiting

```typescript
// Planned implementation
const rateLimiter = new RateLimiter({
  windowMs: 60 * 1000,  // 1 minute
  max: 10,               // 10 requests per minute
});
```

---

## üß™ Testing Strategy

### Unit Tests (Planned)

```typescript
// tests/lib/vectordb.test.ts
describe('Vector Database', () => {
  test('generateChunks creates 32 chunks', () => {
    const chunks = generateChunks();
    expect(chunks.length).toBe(32);
  });
  
  test('searchRelevantContext returns top-k results', async () => {
    const results = await searchRelevantContext('Python experience');
    expect(results.length).toBeLessThanOrEqual(5);
  });
});
```

### Integration Tests (Planned)

```typescript
// tests/api/chat.test.ts
describe('/api/chat', () => {
  test('returns valid response for interview question', async () => {
    const response = await fetch('/api/chat', {
      method: 'POST',
      body: JSON.stringify({ 
        message: 'Tell me about your Python experience' 
      }),
    });
    expect(response.status).toBe(200);
    const data = await response.json();
    expect(data.answer).toBeDefined();
  });
});
```

### Performance Tests (Planned)

```bash
# Artillery load testing
artillery run tests/load/chat-api.yml
```

---

## üìà Monitoring & Observability

### Metrics Collection

```typescript
// lib/analytics.ts
export function logChatInteraction(log: ChatLog) {
  chatLogs.push(log);
  updateMetrics(log);
}

function updateMetrics(log: ChatLog) {
  metrics.totalQuestions++;
  metrics.avgResponseTime = calculateAverage();
  metrics.successRate = calculateSuccessRate();
  metrics.interviewTypeDistribution[log.interviewType]++;
}
```

### Logging Strategy

```
INFO  - Chat interaction logged
INFO  - Vector search completed (300ms)
INFO  - LLM generation completed (1200ms)
ERROR - Groq API rate limit exceeded
WARN  - High response time detected (>3s)
```

### Health Checks (Planned)

```typescript
// app/api/health/route.ts
export async function GET() {
  const checks = {
    upstash: await checkUpstashConnection(),
    groq: await checkGroqAPI(),
    vercel: true,
  };
  
  return Response.json({
    status: Object.values(checks).every(Boolean) ? 'healthy' : 'degraded',
    checks,
    timestamp: new Date().toISOString(),
  });
}
```

---

## üîÑ CI/CD Pipeline

### GitHub Actions Workflow

```yaml
# .github/workflows/deploy.yml
name: Deploy to Vercel

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm install
      - run: npm run build
      - uses: amondnet/vercel-action@v20
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.ORG_ID }}
          vercel-project-id: ${{ secrets.PROJECT_ID }}
```

---

## üõ£Ô∏è Future Architecture Enhancements

### Phase 1: Database Migration (Planned)
- Migrate from in-memory to PostgreSQL/Supabase
- Persistent analytics storage
- User session management

### Phase 2: Advanced Features (Planned)
- Real-time chat with WebSockets
- Voice interview simulation
- Video interview recording
- Multi-language support (i18n)

### Phase 3: ML Enhancements (Planned)
- Fine-tuned model on interview data
- Custom embeddings model
- Answer quality scoring with ML
- Personalized response adaptation

---

**Document Version:** 1.0  
**Last Updated:** October 31, 2025  
**Author:** Douglas Mo  
**Architecture Status:** Production-Ready, v1 Complete
